{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "806b5a4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 22 (3785909514.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 23\u001b[1;36m\u001b[0m\n\u001b[1;33m    with open(filename,'r') as csvfile:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after function definition on line 22\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "print(df)\n",
    "\n",
    "class Node:\n",
    "    def __init__(self,attribute):\n",
    "        self.attribute = attribute\n",
    "        self.children  = []\n",
    "        self.answer = None\n",
    "        \n",
    "    def read_data(filename):\n",
    "       with open(filename,'r') as csvfile:\n",
    "          datareader = csv.reader(csvfile,delimiter=',')\n",
    "          headers = next(datareader)\n",
    "          traindata = [row for row in datareader]\n",
    "       return headers,traindata\n",
    "    \n",
    "    def read_test_data(filename):\n",
    "    with open(filename,'r') as csvfile:\n",
    "        datareader = csv.reader(csvfile,delimiter=',')\n",
    "        testdata = [row for row in datareader]\n",
    "    return testdata\n",
    "    \n",
    "    def subtables(data,col,delete):\n",
    "    dict = {}\n",
    "    items = np.unique(data[:,col])\n",
    "    for item in items:\n",
    "        dict[item] = data[data[:,col]==item]\n",
    "        if delete:\n",
    "            dict[item] = np.delete(dict[item],col,axis = 1)\n",
    "    return items,dict\n",
    "    \n",
    "    def entropy(S):\n",
    "    items,counts = np.unique(S,return_counts = True)\n",
    "    probabilities = counts/len(S)\n",
    "    return -np.sum(probabilities*np.log2(probabilities))\n",
    "    \n",
    "    def gain_ratio(data,col):\n",
    "    total_entropy = entropy(data[:,-1])\n",
    "    items,dict = subtables(data,col,delete=False)\n",
    "    subset_entropy = 0\n",
    "    intrinsic_value = 0\n",
    "    total_size = data.shape[0]\n",
    "    for item in items:\n",
    "        subset = dict[item]\n",
    "        ratio = len(subset)/total_size\n",
    "        subset_entropy += ratio * entropy(subset[:,-1])\n",
    "        intrinsic_value -= ratio * math.log(ratio,2)\n",
    "    if intrinsic_value == 0:\n",
    "        return 0\n",
    "    information_gain = total_entropy - subset_entropy\n",
    "    return information_gain/intrinsic_value\n",
    "    \n",
    "    def create_node(data,metadata):\n",
    "    if len(np.unique(data[:,-1])) == 1:\n",
    "        node = Node(None)\n",
    "        node.answer = np.unique(data[:,-1])[0]\n",
    "        return node\n",
    "    gains = [gain_ratio(data,col) for col in range(data.shape[1] -1)]\n",
    "    split = np.argmax(gains)\n",
    "    node = Node(metadata[split])\n",
    "    items,dict = subtables(data,split,delete = True)\n",
    "    for item in items:\n",
    "        child = create_node(dict[item],np.delete(metadata,split))\n",
    "        node.children.append((item,child))\n",
    "    return node\n",
    "    \n",
    "    def predict(node,instance,metadata):\n",
    "    if node.answer is not None:\n",
    "        return node.answer\n",
    "    value = instance[metadata.index(node.attribute)]\n",
    "    for item,child in node.children:\n",
    "        if item == value:\n",
    "            return predict(child,instance,metadata)\n",
    "            \n",
    "            def empty(size):\n",
    "    return \"   \" * size\n",
    "def print_tree(node,level):\n",
    "    if node.answer is not None:\n",
    "        print(empty(level),node.answer)\n",
    "        return\n",
    "    print(empty(level),node.attribute)\n",
    "    for value,n in node.children:\n",
    "        print(empty(level+1),value)\n",
    "        print_tree(n,level + 2)\n",
    "        \n",
    "        def print_predictions(node,testdata,metadata):\n",
    "    test_instances = testdata[1:]\n",
    "    for instance in test_instances:\n",
    "        prediction = predict(node,instance,metadata)\n",
    "        print(f\"The test instance:{instance}\")\n",
    "        print(f\"The predicted label:{prediction}\")\n",
    "        metadata,traindata = read_data(\"dataset.csv\")\n",
    "        test_data = read_test_data(\"test.csv\")\n",
    "        data = np.array(traindata)\n",
    "        node = create_node(data,metadata)\n",
    "        print(\"Decision tree structure\")\n",
    "        print_tree(node,0)\n",
    "        print(\"\\nPredictions for test data\")\n",
    "        print_predictions(node,test_data,metadata)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
